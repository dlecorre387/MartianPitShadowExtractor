{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc111111-e59e-4d07-a855-d584c713fd2c",
   "metadata": {},
   "source": [
    "# The Pit Topography from Shadows (**PITS**) Tool\n",
    "## Introduction\n",
    "The Pit Topography from Shadows (**PITS**) tool is a dockerised Python framework which can automatically calculate an apparent depth (*h*) profile for Martian or Lunar pits from only one cropped, single- or multi-band, remote-sensing image. *h* is the relative depth of the pit between its rim and the edge of the shadow cast by the Sun - with the principle being that a deeper pit would cast a wider shadow. \n",
    "\n",
    "Pits, or pit craters, are near-circular depressions found in planetary surfaces which are generally formed through gravitational collapse. Pits will be primary targets for future space exploration and habitability, for their presence on most rocky Solar System surfaces and their potential to be entrances to sub-surface cavities.\n",
    "\n",
    "PITS employs image segmentation in the form of *k*-means clustering with silhouette analysis to automatically detect the shadow and measure its width, wherby a *h* profile can be calculated. In addition to the *h* profile, **PITS** saves the extents of the detected shadow as a geo-referenced ESRI shapefile for visualisation in GIS software. This can be used to enhance the contrast of the pixels within the shadow to search for any deeper-shaded regions - possibly due to a cave entrance. **PITS** currently works with Mars Reconnaissance Orbiter (MRO) High Resolution Science Imaging Experiment (HiRISE) and Lunar Reconnaissance Orbiter (LRO) Narrow Angle Camera (NAC) imagery of Mars and the Moon, respectively.\n",
    "\n",
    "Go to **PITS'** [GitHub](https://github.com/dlecorre387/Pit-Topography-from-Shadows/) repository to learn more about how to install the tool, how it works, and its accuracy when tested on MRO HiRISE imagery of Martian pits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f991871-73f6-4724-9be0-e0aa3f2e912a",
   "metadata": {},
   "source": [
    "## PITS - Jupyter Notebook Tutorial\n",
    "Typically, **PITS** is run by executing a Python script, called [`run_PITS.py`](run_PITS.py), within the terminal of a docker container. This script imports the functions from an additional script, called [`PITS_functions.py`](PITS_functions.py), and performs them in the correct order to get the desired outputs. [`PITS_plotter.py`](PITS_plotter.py) is also used for plotting the *h* profiles (since they are normally saved as CSV files) for the entire imagery dataset provided to **PITS**.\n",
    "\n",
    "This Jupyter notebook tutorial has also been compiled in order to better explain the individual elements of the **PITS** algorithm, and how they have been implemented into Python. These steps (that would normally form one large 'for' loop) have been broken down into individual cells such that they can be explained, run in succession, and the result can be viewed afterwards. Consequently, this notebook imports functions from [`PITS_functions_tutorial.py`](PITS_functions_tutorial.py), which have been tailored specifically for this tutorial. \n",
    "\n",
    "In this tutorial, we will be applying the **PITS** tool to the MRO HiRISE image ESP_033342_1660, which contains a Martian pit. Pit location labels (in ESRI shapefile format) have already been provided for cropping this HiRISE image product down to the extents of the pit. Labels of the pit's shadow have also been produced such that the accuracy of **PITS'** automated shadow extraction can be tested. Red-band and colour versions of ESP_033342_1660 are also available, showing the ability of **PITS** to produce *h* profiles for single and multi-band imagery."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29336fc-8877-46a9-ac9c-522dc1a82313",
   "metadata": {},
   "source": [
    "### Importing Packages\n",
    "The cell below imports all necessary python packages and the functions from the [`PITS_functions_tutorial.py`](PITS_functions_tutorial.py) file. It also defines the logger which prints various info/error messages where applicable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a835b-84ea-439f-a5c9-b65a93e4e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Import PITS functions\n",
    "from PITS_functions_tutorial import *\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level = logging.INFO,\n",
    "                    format='| %(asctime)s | %(levelname)s | Message: %(message)s',\n",
    "                    datefmt='%d/%m/%y @ %H:%M:%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6da2e92",
   "metadata": {},
   "source": [
    "### Defining Directory to Input Data\n",
    "In the cell below, the full path to the directory containing the necessary input data to allow **PITS** to run needs to be defined. When running the docker container for the first time, you can either copy the data to a location in the container, mount a local volume to a location in the container, or point to it directly. In this directory, there should be four folders to start with:\n",
    "1. `input` - Contains the input imagery that **PITS** is meant to derived *h* profiles from,\n",
    "2. `labels` - Contains the ESRI shapefile labels of the pit's location (as rectangular polygons) in the image,\n",
    "3. `metadata` - Contains the cumulative PDS3 index file with all the necessary metadata for your images,\n",
    "4. `testing` - Contains the manual ESRI shapefile labels of the pit's shadows for testing shadow extraction performance.\n",
    "\n",
    "When running **PITS** for the first time, a fifth folder will be created, called `output`, which will house all of the outputs of the tool - such as *h* profiles, shapefiles of the detected shadows, and a CSV of all results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full path to the directory containing the necessary input data (ending with a /)\n",
    "data_dir = '/data/'\n",
    "\n",
    "# Check that the data directory exists\n",
    "if not os.path.exists(data_dir):\n",
    "    raise OSError(f\"Directory '{data_dir}' could not be found or does not exist.\")\n",
    "\n",
    "# Check that the folders input, labels, metadata and testing are present\n",
    "folders = ['input/', 'labels/', 'metadata/', 'testing/']\n",
    "for folder in folders:\n",
    "    if os.path.exists(data_dir) and not os.path.exists(os.path.join(data_dir, folder)):\n",
    "        raise OSError(f\"Directory '{os.path.join(data_dir, folder)}' could not be found or does not exist.\")\n",
    "    \n",
    "# Define the full paths to the individual input folders\n",
    "input_dir = os.path.join(data_dir, 'input/')\n",
    "metadata_dir = os.path.join(data_dir, 'metadata/')\n",
    "labels_dir = os.path.join(data_dir, 'labels/')\n",
    "testing_dir = os.path.join(data_dir, 'testing/')\n",
    "output_dir = os.path.join(data_dir, 'output/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660e71f-fd61-4fab-88d4-a8f40bd2b297",
   "metadata": {},
   "source": [
    "### Input Parameters\n",
    "The following cell is where the user needs to define a number of the input parameters for the PITS tool to operate. When running **PITS** in the command line, a number of mandatory and optional arguments can be passed. For this Jupyter notebook to work, these command line arguments are given as variables which the user will need to define. We also add an additional optional argument called `colour`, which will tell **PITS** to run on the red, colour or both versions of ESP_033342_1660."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354769ca-53b4-47c4-92bb-49e997f7568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Required Parameters:\n",
    "\n",
    "dataset:    The name of the dataset whose images will be used to calculate apparent depths.\n",
    "            Currently supported options are \"hirise-rdr\" (for MRO HiRISE RDR version 1.1 \n",
    "            images of Mars) and \"lronac-edr\" (for LROC NAC EDR images of the Moon). This \n",
    "            is required since there is a different process for retrieving sensing \n",
    "            information for each dataset.\n",
    "            (No default / Type: str)\n",
    "\n",
    "cropping:   Crop each larger input image to the extents of the pit feature using user-provided\n",
    "            ESRI shapefile rectangular labels of the pit's location. These shapefiles must \n",
    "            include or be equal to the full product name of the corresponding image file, e.g. \n",
    "            label_ESP_033342_1660_RED.shp for the HiRISE image ESP_033342_1660_RED.JP2.\n",
    "            (No default / Type: bool)\n",
    "'''\n",
    "\n",
    "# Required parameters\n",
    "dataset = None\n",
    "cropping = None\n",
    "\n",
    "# Checking the required parameters are the correct types\n",
    "if dataset != 'hirise-rdr' and dataset != 'lronac-edr' and dataset != None:\n",
    "    raise ValueError(\"Supported options for dataset are 'hirise-rdr' for HiRISE RDRV11 data and 'lronac-edr' for LRO NAC EDR data.\")\n",
    "elif dataset == None:\n",
    "    raise ValueError(\"Please define the variable 'dataset'. Supported options for dataset are 'hirise-rdr' for HiRISE RDRV11 data and 'lronac-edr' for LRO NAC EDR data.\")\n",
    "if cropping != True and cropping != False and cropping != None:\n",
    "    raise ValueError(\"Supported options for 'cropping' are True or False.\")\n",
    "elif cropping == None:\n",
    "    raise ValueError(\"Please define the variable 'cropping'. Supported options for 'cropping' are True or False.\")\n",
    "\n",
    "'''\n",
    "Optional Parameters:\n",
    "\n",
    "colour:     Apply PITS to the red, colour or both versions of the image. Set 'colour' to 'red', \n",
    "            'colour' or 'both', respectively.\n",
    "            (Default: 'both' / Type: str)\n",
    "\n",
    "testing:    Calculate the precision, recall and F1 score of shadow pixel detections in each image \n",
    "            using user-provided ESRI shapefile labels of the pit's shadow. \n",
    "            (Default: True / Type: bool)\n",
    "            \n",
    "factor:     The factor by which the cropped input image and labels will be down-scaled when\n",
    "            calculating the silhouette coefficients during shadow extraction. \n",
    "            (Default: 10 / Type: float)\n",
    "'''\n",
    "\n",
    "# Optional parameters\n",
    "colour = 'both'\n",
    "testing = True\n",
    "factor = 10\n",
    "\n",
    "# Checking that 'colour' is one of the options\n",
    "if colour not in ['red', 'colour', 'both']:\n",
    "    raise ValueError(\"Variable 'colour' must be equal to 'red', 'colour' or 'both'.\")\n",
    "\n",
    "# Check that 'testing' is a boolean\n",
    "if not isinstance(testing, bool):\n",
    "    raise ValueError(\"Variable 'testing' must be a boolean.\")\n",
    "\n",
    "# Checking that 'factor' is a float and more than one\n",
    "if not isinstance(factor, float) and not isinstance(factor, int):\n",
    "    raise ValueError(\"Variable 'factor' must be a int/float.\")\n",
    "if factor < 1:\n",
    "    raise ValueError(\"Variable 'factor' must be larger than 1.\")\n",
    "\n",
    "# Do not change these variables\n",
    "cluster_range = np.arange(4, 14, 1)\n",
    "miss_rates = [0.004280421, 0.00611175]\n",
    "FD_rates = [0.052279632, 0.059128667]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c19d203-63b6-48ec-b0d1-9bb9283d1c3c",
   "metadata": {},
   "source": [
    "### Creating and Cleaning Output Directory\n",
    "This cell creates the directory where **PITS'** outputs will be stored, or cleans it if it already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7332612b-458b-48d6-8422-210ac99e0176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean or create output folder\n",
    "if os.path.exists(output_dir):\n",
    "    for file in os.listdir(output_dir):\n",
    "        file_path = os.path.join(output_dir, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file, e))\n",
    "    logging.info(f\"Output folder '{output_dir}' cleaned.\")\n",
    "elif not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    logging.info(f\"Output folder '{output_dir}' created.\")\n",
    "   \n",
    "# Create sub-folders for separating, h profiles, shadow shapefiles and other results\n",
    "profiles_dir = os.path.join(output_dir, 'profiles/')\n",
    "shadows_dir = os.path.join(output_dir, 'shadows/')\n",
    "subfolders = [profiles_dir, shadows_dir]\n",
    "for subfolder in subfolders:\n",
    "    if not os.path.exists(subfolder):\n",
    "        try:\n",
    "            os.makedirs(subfolder)\n",
    "        except Exception as e:\n",
    "            print('Failed to create subfolder %s. Reason %s' % (subfolder, e))\n",
    "logging.info(f\"Sub-folders created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cb126c-ffca-4d10-88ba-bdb2f6427ac2",
   "metadata": {},
   "source": [
    "### Opening Arrays for Storing Results\n",
    "Since we know the number of images in the input directory that **PITS** is to be applied to, we can open some empty arrays to save run-time when storing information (to be saved as a CSV later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57822f23-9427-4542-81d9-3bf548a4e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all filenames to be analysed without XML or TXT files\n",
    "filenames = [file for file in os.listdir(input_dir) if not file.endswith('.xml') if not file.endswith('.txt')]\n",
    "\n",
    "# Filter the list of filenames depending on if PITS will be applied to red and/or colour images\n",
    "if colour == 'red':\n",
    "    filenames = [filename for filename in filenames if 'RED' in filename]\n",
    "elif colour == 'colour':\n",
    "    filenames = [filename for filename in filenames if 'COLOR' in filename]\n",
    "\n",
    "logging.info(f\"The following files will be analysed ({len(filenames)} in total):\")\n",
    "for file_n, filename in enumerate(filenames):\n",
    "    print(f\"File {file_n+1}:     {filename}\")\n",
    "\n",
    "# Open empty arrays to store sensing info\n",
    "resolutions = np.empty((len(filenames)))\n",
    "inc_angles = np.empty((len(filenames)))\n",
    "solar_azim_angles = np.empty((len(filenames)))\n",
    "sc_azim_angles = np.empty((len(filenames)))\n",
    "em_angles = np.empty((len(filenames)))\n",
    "delta_em_angles = np.empty((len(filenames)))\n",
    "em_angle_pars = np.empty((len(filenames)))\n",
    "em_angle_perps = np.empty((len(filenames)))\n",
    "phase_angles = np.empty((len(filenames)))\n",
    "\n",
    "# Open empty arrays to store the centre and maximum apparent depths (h)\n",
    "centre_hs = np.empty((len(filenames)))\n",
    "pos_centre_hs = np.empty((len(filenames)))\n",
    "neg_centre_hs = np.empty((len(filenames)))\n",
    "max_hs = np.empty((len(filenames)))\n",
    "pos_max_hs = np.empty((len(filenames)))\n",
    "neg_max_hs = np.empty((len(filenames)))\n",
    "\n",
    "# Set up arrays for storing testing metrics\n",
    "if testing:\n",
    "    P_shadow = np.empty(len(filenames))\n",
    "    R_shadow = np.empty(len(filenames))\n",
    "    F1_shadow = np.empty(len(filenames))\n",
    "\n",
    "# Store the silhouette coefficients/scores\n",
    "silhouettes = np.empty((len(filenames), len(cluster_range)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e93da-a1dc-42d5-87e7-64f3e2cf7824",
   "metadata": {},
   "source": [
    "### Cropping Larger Image Products and Reading Image Metadata\n",
    "In this cell, all larger image products are cropped using the pit location shapefile labels. It will also read in all the relevant sensing information and sensor data from the PDS3 cumulative index file which should be placed in the metadata directory before building the docker image. These files can be retrieved from NASA's Planetary Data System ([PDS](https://pds.nasa.gov/)) and filtered to the relevant images using the BASH script [`filter_index_files.sh`](filter_index_files.sh) provided along with **PITS**. This greatly improves the run-time as without this, **PITS** has to look through several thousand lines of a text file to find the correct row of metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c9da3a-a703-40a1-8663-33c697266cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open progress bar\n",
    "pbar = tqdm(total=len(filenames), desc='Progress')\n",
    "\n",
    "# Loop through each image\n",
    "for i, filename in enumerate(filenames):\n",
    "        \n",
    "    # Initialise DataPreparer class\n",
    "    DataPrep = DataPreparer(filename=filename,\n",
    "                            input_dir=input_dir, \n",
    "                            metadata_dir=metadata_dir,\n",
    "                            labels_dir=labels_dir,\n",
    "                            testing_dir=testing_dir,\n",
    "                            output_dir=output_dir)\n",
    "    \n",
    "    if cropping:\n",
    "        \n",
    "        # Crop the image using provided shapefile labels and return raster information [resolution in m, lat/lon in deg]\n",
    "        cropped_image, resolution, min_longitude, max_longitude, min_latitude, max_latitude, geotransform, projection, n_bands, x_size, y_size = DataPrep.crop_image()\n",
    "\n",
    "        # Retrieve sensing angles at time of acquisition [in radians]\n",
    "        inc_angle, solar_azim_angle, sc_azim_angle, phase_angle, em_angle, delta_em_angle, em_angle_par, em_angle_perp = DataPrep.read_metadata(dataset, min_longitude, max_longitude, min_latitude, max_latitude)\n",
    "        \n",
    "    elif not cropping:\n",
    "        \n",
    "        # Retrieve sensing angles at time of acquisition [in radians]\n",
    "        inc_angle, solar_azim_angle, sc_azim_angle, phase_angle, em_angle, delta_em_angle, em_angle_par, em_angle_perp = DataPrep.read_metadata(dataset, None, None)\n",
    "    \n",
    "    # Store metadata in arrays for saving later\n",
    "    resolutions[i], inc_angles[i], solar_azim_angles[i], sc_azim_angles[i], phase_angles[i], em_angles[i], delta_em_angles[i], em_angle_pars[i], em_angle_perps[i] = resolution, inc_angle, solar_azim_angle, sc_azim_angle, phase_angle, em_angle, delta_em_angle, em_angle_par, em_angle_perp\n",
    "\n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "if cropping:\n",
    "    logging.info(\"All images cropped and metadata acquired.\")\n",
    "elif not cropping:\n",
    "    logging.info(\"All metadata acquired.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170f9a9f-b778-4b85-b42c-67268ec7c372",
   "metadata": {},
   "source": [
    "### Automated Shadow Extraction\n",
    "**PITS** employs *k*-means clustering with silhouette analysis to segment each image into *k* number of clusters. This means that each individual pixel in the input image is assigned a cluster label from 0 to *k* - 1. If **PITS** is applied to multi-band images, each band is clustered separately and the modal cluster label for each pixel across all bands is then assigned. The darkest cluster (as it appears in the input image) is then extracted and classified as the shadow. Silhouette analysis is used to automatically select the value for *k* which returns the darkest cluster which is the most consistent within itself, and  the most distinct from all other clusters. This results in a binary mask, where shadow and background pixels are assigned a 1 and 0, respectively.\n",
    "\n",
    "Some post-processing is then performed on this binary shadow mask, as to ensure a correct shadow width measurement later on. Firstly, the largest continuous shadow is separated, with all others being removed from the mask (i.e. assigned to background). This is to filter out any small shadows cast by features such as boulders rather than the shadow's rim. Then in order to remove any noisy bright pixels from the shadow, **PITS** performs morphological closing on all holes encased within the shadow mask with an area less than 10 pixels. Any remaining holes in the shadow are expected to be bright features (again, such as boulders) which are protruding above the shadow. Shadow pixels cast by these features are removed later on in the algorithm, as to not over estimate the depth of the pit at these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e43cf8-30dd-4311-a116-a2087153bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-define the input directory if images were cropped earlier\n",
    "if cropping:\n",
    "    input_dir = os.path.join(output_dir, 'cropped/')\n",
    "\n",
    "# List all filenames to be analysed without .XML files\n",
    "filenames = [file for file in os.listdir(input_dir) if not file.endswith('.xml')]\n",
    "\n",
    "# Filter the list of filenames depending on if PITS will be applied to red and/or colour images\n",
    "if colour == 'red':\n",
    "    filenames = [filename for filename in filenames if 'RED' in filename]\n",
    "elif colour == 'colour':\n",
    "    filenames = [filename for filename in filenames if 'COLOR' in filename]\n",
    "\n",
    "# Open progress bar\n",
    "pbar = tqdm(total=len(filenames)*cluster_range.size, desc='Progress')\n",
    "\n",
    "# Loop through each image\n",
    "for i, filename in enumerate(filenames):\n",
    "    \n",
    "    # Get the product identification of the image from the filename\n",
    "    name = os.path.splitext(filename)[0]\n",
    "\n",
    "    # Initialise DataPreparer class\n",
    "    DataPrep = DataPreparer(filename=filename,\n",
    "                            input_dir=input_dir, \n",
    "                            metadata_dir=metadata_dir,\n",
    "                            labels_dir=labels_dir,\n",
    "                            testing_dir=testing_dir,\n",
    "                            output_dir=output_dir)\n",
    "\n",
    "    # Read the cropped image and return raster information [resolution in m]\n",
    "    cropped_image, _, _, _, n_bands, x_size, y_size = DataPrep.read_cropped_im()\n",
    "\n",
    "    # Open an empty array to store the all the sorted labels for each value of k   \n",
    "    all_sorted_labels = np.empty((len(cluster_range), x_size, y_size))\n",
    "\n",
    "    # Loop over different numbers of kmeans clusters and shadow cluster threshold\n",
    "    for c, n_clusters in enumerate(cluster_range):\n",
    "\n",
    "        # Cluster the image and sort the labels for a single-band image\n",
    "        if n_bands == 1:\n",
    "            \n",
    "            # Initialise the ShadowExtractor class\n",
    "            ShadExt = ShadowExtractor(cropped_image=cropped_image,\n",
    "                                    n_clusters=n_clusters,\n",
    "                                    factor=factor)\n",
    "            \n",
    "            # Cluster image so that each pixel is assigned a label\n",
    "            labels = ShadExt.kmeans_clustering()\n",
    "            \n",
    "            # Sort the labels by brightness\n",
    "            sorted_labels = ShadExt.sort_clusters(labels)\n",
    "            \n",
    "            # Calculate and save the average silhouette coefficient for the darkest cluster\n",
    "            silhouettes[i, c] = ShadExt.calc_silh_coefficient(sorted_labels)\n",
    "                \n",
    "        # Cluster and sort the labels of each band in a multi-band image\n",
    "        elif n_bands > 1:\n",
    "            \n",
    "            # Store the silhouette coefficient/score and labels for each band\n",
    "            band_silhouettes = np.empty((n_bands))\n",
    "            band_labels = np.empty((n_bands, x_size, y_size))\n",
    "            \n",
    "            # Loop through each band\n",
    "            for band in np.arange(n_bands):\n",
    "                \n",
    "                # Initialise the ShadowExtractor class\n",
    "                ShadExt = ShadowExtractor(cropped_image=cropped_image[band, :, :],\n",
    "                                        n_clusters=n_clusters,\n",
    "                                        factor=factor)\n",
    "                \n",
    "                # Cluster the individual band so that each pixel is assigned a label\n",
    "                labels = ShadExt.kmeans_clustering()\n",
    "                \n",
    "                # Sort the labels for this band by brightness\n",
    "                band_labels[band, :, :] = ShadExt.sort_clusters(labels)\n",
    "                \n",
    "                # Calculate and save the average silhouette coefficient for the darkest cluster\n",
    "                band_silhouettes[band] = ShadExt.calc_silh_coefficient(band_labels[band, :, :])\n",
    "            \n",
    "            # Average the silhouette coefficients/scores across the bands\n",
    "            silhouettes[i, c] = np.mean(band_silhouettes)\n",
    "                \n",
    "            # Calculate modal labels if applied to colour images\n",
    "            sorted_labels = (mode(band_labels, axis=0).mode).astype(int)\n",
    "        \n",
    "        else:\n",
    "            raise ValueError(\"Number of bands should not be zero.\")\n",
    "        \n",
    "        # Store the sorted labels for later and save the number of iterations for this value of k\n",
    "        all_sorted_labels[c, :, :] = sorted_labels\n",
    "\n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "    # Find the labels for k which gave the highest silhouette coefficient/score\n",
    "    ind = int(np.argmax(silhouettes[i, :]))\n",
    "\n",
    "    # Use the labels which maximised the darkest clusters silhouette coefficient\n",
    "    raw_shadow = np.where(all_sorted_labels[ind, :, :] == np.amin(all_sorted_labels[ind, :, :]), 1, 0)\n",
    "    \n",
    "    # Initialise the PostProcessor class\n",
    "    PostProc = PostProcessor(shadow=raw_shadow)\n",
    "    \n",
    "    # Remove all small shadow detections so only the main shadow remains, then detect and fill bright features in shadow mask\n",
    "    main_shadow, filled_shadow = PostProc.post_processing()\n",
    "\n",
    "    # Compare the detected shadows to the manually-labelled shadow shapefiles to get testing metrics\n",
    "    if testing:\n",
    "    \n",
    "        # Read in ground truth if testing\n",
    "        true_shadow, _ = DataPrep.read_ground_truth(n_bands, cropped_image, geotransform, projection)\n",
    "                \n",
    "        # Initialise ShadowTester class\n",
    "        ShadTest = ShadowTester(main_shadow=main_shadow,\n",
    "                                true_shadow=true_shadow)\n",
    "    \n",
    "        # Calculate and store the precision, recall and F1 scores\n",
    "        P_shadow[i], R_shadow[i], F1_shadow[i] = ShadTest.calc_shadow_metrics()\n",
    "        \n",
    "        # Plot the detected shadow and colour-code it (R: FP, G: TP, B: FN)\n",
    "        non_shadow = np.where(true_shadow == 0, 1, 0)\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax1.imshow(true_shadow, cmap='gray', interpolation='none')\n",
    "        ax1.axis('off')\n",
    "        ax1.set_title(f\"Shadow 'Ground Truth' for\\n{name}\")\n",
    "        ax2.imshow(main_shadow, cmap='gray', interpolation='none')\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title(f\"Extracted Shadow for\\n{name}\")\n",
    "        colour_array = np.empty((x_size, y_size, 3))\n",
    "        colour_array[:, :, 0] = np.where(main_shadow * non_shadow == 1, 1, 0)\n",
    "        colour_array[:, :, 1] = np.where(main_shadow * true_shadow == 1, 1, 0)\n",
    "        colour_array[:, :, 2] = np.where(true_shadow - main_shadow == 1, 1, 0)\n",
    "        mask = np.sum(colour_array, axis=2) == 0\n",
    "        colour_array[mask, :] = 1\n",
    "        ax3.imshow(colour_array, interpolation='none')\n",
    "        ax3.axis('off')\n",
    "        ax3.set_title(f\"Shadow Extraction Performance for\\n{name}\")\n",
    "        plt.show()\n",
    "\n",
    "    # Save the shadow as a geo-referenced shapefile\n",
    "    DataPrep.save_shadow(main_shadow, filled_shadow, geotransform, projection)\n",
    "\n",
    "    # Plot the input image and detected shadow\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15,5))\n",
    "    if n_bands == 1:\n",
    "        ax1.imshow(cropped_image, cmap='gray', aspect='equal', interpolation='none')\n",
    "        ax1.set_title(f\"{name}\")\n",
    "    elif n_bands > 1:\n",
    "        ax1.imshow(cropped_image[0, :, :], cmap='gray', aspect='equal', interpolation='none')\n",
    "        ax1.set_title(f\"{name} (Red Band Only)\")\n",
    "    ax1.axis('off')\n",
    "    ax2.imshow(all_sorted_labels[ind, :, :], aspect='equal', interpolation='none')\n",
    "    ax2.axis('off')\n",
    "    ax2.set_title(r\"$k$-means Clusters\")\n",
    "    ax3.imshow(main_shadow, cmap='gray', aspect='equal', interpolation='none')\n",
    "    ax3.axis('off')\n",
    "    ax3.set_title(\"Detected Main Shadow\")\n",
    "    plt.show()\n",
    "    \n",
    "pbar.close()\n",
    "\n",
    "if testing:\n",
    "    logging.info(f\"Shadows automatically extracted from all input images, processed, tested and saved to {shadows_dir}\")\n",
    "\n",
    "elif not testing:\n",
    "    logging.info(f\"Shadows automatically extracted from all input images, processed and saved to {shadows_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511960fd-019f-4da4-81ad-1ee4ae6be627",
   "metadata": {},
   "source": [
    "### Calculate Apparent Depth (*h*) Profiles\n",
    "**PITS** rotates the binary shadow mask by the Sun's azimuth angle relative to North ($\\varphi$). It can then measure the width of the shadow along the Sun's line of sight as observed by the satellite (*S<sub>obs</sub>*) at each pixel in the shadows length. *S<sub>obs</sub>* is then corrected for non-nadir observations to obtain the true shadow width (*S<sub>true</sub>*) as if the satellite was pointing straight downwards at the surface. *h* is then derived from these *S<sub>true</sub>* measurements by considering the incidence angle of the Sun ($\\alpha$) for this particular image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe93c64-4e07-4ff1-8759-8d2dbf1c6546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open progress bar\n",
    "pbar = tqdm(total=len(filenames), desc='Progress')\n",
    "\n",
    "# Loop through each image\n",
    "for i, filename in enumerate(filenames):\n",
    "    \n",
    "    # Get the product identification of the image from the filename\n",
    "    name = os.path.splitext(filename)[0]\n",
    "\n",
    "    # Recalculate miss and false discovery rates if testing\n",
    "    if testing:    \n",
    "        \n",
    "        # Use the errors (miss rate and FD rate) calculated by comparing to the ground truth\n",
    "        miss_rate = 1 - R_shadow[i]\n",
    "        FD_rate = 1 - P_shadow[i]\n",
    "    \n",
    "    # Don't recalculate miss and false discovery rates if no testing\n",
    "    elif not testing:\n",
    "        \n",
    "        # Retrieve the correct miss and false discovery rates for the number of bands\n",
    "        if n_bands == 1:\n",
    "            miss_rate, FD_rate = miss_rates[0], FD_rates[0]\n",
    "        elif n_bands > 1:\n",
    "            miss_rate, FD_rate = miss_rates[1], FD_rates[1]\n",
    "        else:\n",
    "            raise ValueError(\"Number of bands should not be zero.\")\n",
    "\n",
    "    # Initialise DataPreparer class\n",
    "    DataPrep = DataPreparer(filename=filename,\n",
    "                            input_dir=input_dir, \n",
    "                            metadata_dir=metadata_dir,\n",
    "                            labels_dir=labels_dir,\n",
    "                            testing_dir=testing_dir,\n",
    "                            output_dir=output_dir)\n",
    "    \n",
    "    # Read in the main shadow\n",
    "    main_shadow = DataPrep.read_shadow('main_shadow')\n",
    "    filled_shadow = DataPrep.read_shadow('filled_shadow')\n",
    "    \n",
    "    # If no bright features were found within the shadow mask\n",
    "    if filled_shadow is None:\n",
    "    \n",
    "        # Initialise the DepthCalculator class\n",
    "        DepCalc = DepthCalculator(shadow_list=[main_shadow],\n",
    "                                resolution=resolutions[i],\n",
    "                                inc_angle=inc_angles[i],\n",
    "                                em_angle=em_angles[i],\n",
    "                                em_angle_par=em_angle_pars[i],\n",
    "                                em_angle_perp=em_angle_perps[i],\n",
    "                                solar_azim_angle=solar_azim_angles[i],\n",
    "                                phase_angle=phase_angles[i])\n",
    "        \n",
    "        # Align the main shadow to the Sun's line of sight\n",
    "        aligned_shadow = DepCalc.align_shadow()\n",
    "        \n",
    "        # Measure the observed shadow widths of the aligned shadow [in m]\n",
    "        S_obs, coords, edge, rim = DepCalc.measure_shadow(aligned_shadow)\n",
    "        S_obs = S_obs[S_obs != 0]\n",
    "        \n",
    "        # Calculate the upper and lower bounds of the uncertainty in the observed shadow width [in m]\n",
    "        pos_delta_S_obs = miss_rate * S_obs\n",
    "        neg_delta_S_obs = FD_rate * S_obs\n",
    "        \n",
    "    # If there were bright features found within the shadow mask\n",
    "    elif filled_shadow is not None:\n",
    "        \n",
    "        # Initialise the DepthCalculator class\n",
    "        DepCalc = DepthCalculator(shadow_list=[main_shadow, filled_shadow],\n",
    "                                resolution=resolutions[i],\n",
    "                                inc_angle=inc_angles[i],\n",
    "                                em_angle=em_angles[i],\n",
    "                                em_angle_par=em_angle_pars[i],\n",
    "                                em_angle_perp=em_angle_perps[i],\n",
    "                                solar_azim_angle=solar_azim_angles[i],\n",
    "                                phase_angle=phase_angles[i])\n",
    "        \n",
    "        # Align the main (non-filled) and filled shadows to the Sun's line of sight\n",
    "        aligned_main_shadow, aligned_filled_shadow = DepCalc.align_shadow()\n",
    "        \n",
    "        # Filter out all shadow pixels which may be caused by bright features within the main shadow\n",
    "        aligned_filtered_shadow = DepCalc.remove_bright_features(aligned_main_shadow, aligned_filled_shadow)\n",
    "        \n",
    "        # Measure the observed shadow widths of the filtered shadow [in m]\n",
    "        S_obs_filtered, coords_filtered, edge_filtered, rim_filtered = DepCalc.measure_shadow(aligned_filtered_shadow)\n",
    "        \n",
    "        # Measure the observed shadow widths of the filled shadow [in m]\n",
    "        S_obs_filled, coords_filled, edge_filled, rim_filled = DepCalc.measure_shadow(aligned_filled_shadow)\n",
    "        \n",
    "        # Find and remove elements where both of the filtered and filled observed width measurements are zero\n",
    "        zero_filter = np.logical_and(S_obs_filtered != 0, S_obs_filled != 0)\n",
    "        S_obs_filtered = S_obs_filtered[zero_filter]\n",
    "        S_obs_filled = S_obs_filled[zero_filter]\n",
    "        \n",
    "        # Calculate the average of the filled and filtered observed shadow widths [in m]\n",
    "        S_obs = (S_obs_filled + S_obs_filtered) / 2\n",
    "        \n",
    "        # Calculate the upper and lower bounds of the averaged observed shadow width [in m]\n",
    "        pos_delta_S_obs = np.maximum(S_obs_filled, S_obs_filtered) - S_obs + (S_obs * miss_rate)\n",
    "        neg_delta_S_obs = S_obs - np.minimum(S_obs_filled, S_obs_filtered) + (S_obs * FD_rate)                \n",
    "    \n",
    "    # Calculate the observed apparent depth before correcting the shadow width [in m]\n",
    "    h_obs = DepCalc.calculate_h(S_obs)\n",
    "    \n",
    "    # Calculate the observed length of the shadow [in m]\n",
    "    L_obs = resolution * np.arange(0, S_obs.size)\n",
    "    \n",
    "    # Find the true shadow width and length by correcting for the satellite emission angle [in m]\n",
    "    S_true, L_true = DepCalc.correct_shadow_width(S_obs, L_obs)\n",
    "    \n",
    "    # Calculate the true apparent depth now that the width has been corrected [in m]\n",
    "    h_true = DepCalc.calculate_h(S_true)\n",
    "    \n",
    "    # Propagate the uncertainties in S_obs and the emission angle to h_true\n",
    "    pos_delta_h_obs, neg_delta_h_obs, pos_delta_h_true, neg_delta_h_true = DepCalc.propagate_uncertainties(S_obs, pos_delta_S_obs, neg_delta_S_obs, delta_em_angles[i])\n",
    "    \n",
    "    # Save the apparent depth profile as a CSV file for plotting later\n",
    "    DataPrep.save_h_profile(L_obs, h_obs, pos_delta_h_obs, neg_delta_h_obs, L_true, h_true, pos_delta_h_true, neg_delta_h_true)\n",
    "        \n",
    "    # Find the centre apparent depths to add to the results table\n",
    "    ind = int(h_true.size / 2)\n",
    "    centre_hs[i], pos_centre_hs[i], neg_centre_hs[i] = h_true[ind], pos_delta_h_true[ind], neg_delta_h_true[ind]\n",
    "    \n",
    "    # Find the maximum apparent depths to add to the results table\n",
    "    max_hs[i], pos_max_hs[i], neg_max_hs[i] = np.amax(h_true), np.amax(pos_delta_h_true), np.amax(neg_delta_h_true)\n",
    "    \n",
    "    # Plot the apparent depth profile\n",
    "    max_depth = np.amax(h_true) + pos_delta_h_true[np.argmax(h_true)]\n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    ax.set_aspect('equal')\n",
    "    ax.plot(L_obs, h_obs, 'r--', alpha=0.5, label=r'$h_{obs}$')\n",
    "    ax.fill_between(L_obs, h_obs - neg_delta_h_obs, h_obs + pos_delta_h_obs, alpha=0.1, color='red', label=r'$\\Delta h_{obs}$')\n",
    "    ax.plot(L_true, h_true, color='green', label=r'$h$')\n",
    "    ax.fill_between(L_true, h_true - neg_delta_h_true, h_true + pos_delta_h_true, alpha=0.4, color='green', label=r'$\\Delta h$')\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=4, frameon=False)\n",
    "    ax.set_xlim(L_true[0], L_true[-1])\n",
    "    ax.set_ylim(0, np.ceil(max_depth / 10)*10)\n",
    "    ax.set_xlabel(r\"Shadow length ($L$) [m]\")\n",
    "    ax.set_ylabel(r\"Apparent depth ($h$) [m]\")\n",
    "    ax.set_title(\"Apparent Depth Profile\\nfor {}\".format(name))\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()\n",
    "\n",
    "    # Update the progress bar\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de520f77",
   "metadata": {},
   "source": [
    "## Saving Results\n",
    "Lastly, PITS saves the results and corresponding sensing information for each image to a CSV file. If the automatically detected shadows have also been compared with manually produced labels, then the performance metrics are also saved to a separate CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc112ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save testing performances\n",
    "if testing:\n",
    "\n",
    "    logging.info(\"Shadow extraction performance metrics:\")\n",
    "    logging.info(\"Average miss rate: {}\".format(1 - np.mean(R_shadow)))\n",
    "    logging.info(\"Average false discovery rate: {}\".format(1 - np.mean(P_shadow)))\n",
    "    logging.info(\"Average F1 score: {}\".format(np.mean(F1_shadow)))\n",
    "\n",
    "    # Store testing results in a structured array\n",
    "    dt = np.dtype([('i', 'U32'), ('P_shadow', float), ('R_shadow', float), ('F1_shadow', float)])\n",
    "    array = np.empty(len(filenames), dtype=dt)\n",
    "\n",
    "    # Store the filenames, and the corresponding testing metrics\n",
    "    array['i'] = [os.path.splitext(filename)[0] for filename in filenames]\n",
    "    array['P_shadow'] = P_shadow\n",
    "    array['R_shadow'] = R_shadow\n",
    "    array['F1_shadow'] = F1_shadow\n",
    "\n",
    "    # Save to a csv file with appropriate headers for reference\n",
    "    np.savetxt(os.path.join(output_dir, 'PITS_testing.csv'), \n",
    "            array,\n",
    "            delimiter=',',\n",
    "            fmt='%s, %f, %f, %f',\n",
    "            header='Image Name, Precision, Recall, F1 Score')\n",
    "    \n",
    "    logging.info(\"Shade extraction performance tested for all {} images and outputs saved to {}\".format(len(filenames), output_dir))\n",
    "\n",
    "# Store results and image information in a structured array\n",
    "dt = np.dtype([('filename', 'U32'),\n",
    "                ('res', float), ('inc', float), ('s_azim', float), ('em', float), ('sc_azim', float),\n",
    "                ('h_c', float), ('pos_h_c', float), ('neg_h_c', float),\n",
    "                ('h_m', float), ('pos_h_m', float), ('neg_h_m', float)])\n",
    "array = np.empty(len(filenames), dtype=dt)\n",
    "\n",
    "# Store filenames and sensing information\n",
    "array['filename'] = [os.path.splitext(filename)[0] for filename in filenames]\n",
    "array['res'] = resolutions * (180 / np.pi)\n",
    "array['inc'] = inc_angles * (180 / np.pi)\n",
    "array['s_azim'] = solar_azim_angles * (180 / np.pi)\n",
    "array['em'] = em_angles * (180 / np.pi)\n",
    "array['sc_azim'] = sc_azim_angles * (180 / np.pi)\n",
    "\n",
    "# Store the corrected apparent depths (and uncertainties) at the shadow's centre\n",
    "array['h_c'] = centre_hs\n",
    "array['pos_h_c'] = pos_centre_hs\n",
    "array['neg_h_c'] = neg_centre_hs\n",
    "\n",
    "# Store the corrected maximum apparent depths (and uncertainties)\n",
    "array['h_m'] = max_hs\n",
    "array['pos_h_m'] = pos_max_hs\n",
    "array['neg_h_m'] = neg_max_hs\n",
    "\n",
    "# Save to a csv file with appropriate headers for reference\n",
    "np.savetxt(os.path.join(output_dir, 'PITS_results.csv'), \n",
    "        array,\n",
    "        delimiter=',',\n",
    "        fmt='%s, %f, %f, %f, %f, %f, %f, %f, %f, %f, %f, %f',\n",
    "        header='Image Name, Resolution [m], Incidence Angle [deg], Solar Azimuth Angle [deg], Emission Angle [deg], Spacecraft Azimuth Angle [deg], Centre h [m], +, -, Maximum h [m], +, -')\n",
    "\n",
    "logging.info(\"All {} images analysed and outputs saved to {}\".format(len(filenames), output_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff314b5",
   "metadata": {},
   "source": [
    "## Acknowledgements\n",
    "This project is part of the Europlanet 2024 RI which has received funding from the European Union’s Horizon 2020 research and innovation programme under grant agreement No 871149."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
